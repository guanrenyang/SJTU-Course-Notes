**计算机系统结构复习笺注**

[TOC]



# 计算机系统性能指标

## Lecture 1 Performance Measure

### CPU性能工具——两个性能指标

执行时间与吞吐率**互相关联**, 使用更快的CPU可以同时优化二者, 但是使用更多CPU只能增加吞吐率不能缩短执行时间.

#### 执行时间（Execution Time）or 响应时间（Response Time）*公式*

计算机**执行某项任务的总时间**，又被成为**墙上时钟时间**，时间越长，性能越差：

$性能=\frac{1}{执行时间}$

#### 性能加速比(Speed up) *公式*

加速比为**改进后**与**改进前**的**性能之比**, 即**时间之比的倒数**

$加速比=\frac{性能X}{性能Y}=\frac{执行时间Y}{执行时间X}$

*注意: 加速比和性能提升比不同*

#### CPU执行时间(CPU Time) ----用于CPU的性能比较

$CPU\ Time(CPU执行时间)=IC(执行的指令数目)\times CPI(clock\ per\ instruction,执行一条指令的时间)\times Clock\ Time(一个时钟周期的长度)$

**降低Clock Time**：深度流水

**降低CPI**：增加流水线。**问题**：流水线之间有依赖性（dependence）因此有停顿，每条流水线**段数越多**，则CPI**越低**。

**降低IC**：1. 编译优化 2. 使用复杂ISA 

#### 吞吐率（Throughput）

**带宽: **单位时间内完成的任务数量

#### CPU吞吐率

1. **MIPS** Million Instruction Per Second，每秒执行的百万条指令数

   $MIPS=一周期完成的指令条数\times 时钟频率(\frac{1}{Clock\ time}))$

2. **FLOPS** Floating Point Operation Per Second，每秒的浮点运算次数

### Amdahl定律

加快某部件执行速度所获得的系统性能加速比，受限于该部件在系统中所占的重要性比例。**如果只针对某一部分优化，是有上限的。且改进越多，系统获得的效果越小**

$P$：被本次优化所影响的部分比例

$S$：性能加速比

$系统总加速比=\frac{总执行时间_{改进前}}{总执行时间_{改进后}}=\frac{1}{(1-P)+\frac{P}{S}}\rightarrow\frac{1}{1-P}$

通常计算机的性能提升**受限于必须串行执行部分的限制**。

经典的Amdahl定律**不适用**于**规模可扩展**的并行应用的性能分析

# 数的表示和运算

## Lecture 02 bits ints

有符号数和无符号数的**乘法**, **加法**, **溢出**完全一样.

### 补码

1. **原因**：
   1. 0唯一表示
   2. 减法转化为加法（被减数+（-减数））
   3. 符号位参与运算
2. **补码表示法**
   1. 负数**取反加一**
   2. 从最低为开始，除了0和第一个1，地其余位（从第二个1开始的1）取反编码
3. **补码加减法**：减一个数等于加这个数的补码。

### 整数加法、溢出判断

 1. **加法**：补码加减法。
 2. **溢出判断**: 编译器不会自动检查溢出.
  3. **溢出检测方法:**
      	1. 符号位判断. 问题在于*一定要等到结果产生后才能判断溢出*
        2. 进位位 相 异或: 当**最高位**和**次高位****只有一位有进位**则代表发生错误. 
        3. 扩展符号位为00或11, 当结果为01和10时代表溢出.

*注意: 最高位的丢弃并不一定是溢出*

​		4. **避免溢出的方法:** 增加位数来表示数据

### 无符号整数

C语言中将位数少的扩展位位数多的.

### 整数乘法

1. **整数乘法**

   ​	两个$w$位操作数的乘积为$2w$位, 最终结果保留**低$w$位**.抛弃高$w$为使用$mod\ 2^w$来实现

   ​	没有**补码乘法公式**, **补码直接进行乘法运算, 结果正确!!!**

2. 乘法溢出.

   **编译器不检测, 需要程序员自己检测**

   **乘法溢出的检测: **

   ```c++
   int m=x*y;	
   return !x || m/x==y;// 当x不为0时检验乘法可逆
   ```

### 常量乘法和除法的优化: Shift Left and Right

通过**左移**实现**乘2**的操作, *对于无符号数和有符号数均有效*, 这比乘法计算更快.

**右移:** 实现**2的幂次作为除数**的除法. 因为右移运算**向下($-\infty$)舍入**

可以使用**修正+右移**的方法实现除法:

1. 对于**正数**或**无符号数**, 本因向下舍入
2. 对于**负数**,**先加上$2^k-1$**再右移$k$位, 以实现**向0舍入**.

## Lecture 03 Floating Point

1. **将precision和range区分开**, 可以表示很大的数但是精确度低,也可以
2. **浮点数有精度问题**, 大数-/+小数可能忽略小数, **代码中不要判断浮点数是否相等** 

**浮点数的作用**:
1. 表示*实数*
2. 表示*很大的数*

**浮点数的缺点**: 不能表示精确的数.

### IEEE754 浮点数

#### 表达形式

##### **十进制科学计数法:**

 1. **规格化Normalized:** 小数点前面没有0

 2. **非规格化: **小数点前面任意

    **对比**: 标准:$1.0\times 10^{-9}$, 非标准$0.1\times 10^{-8}$

##### **二进制科学计数法**

$1.01_{2}\times 2^{-1}$

尾数mantissa:1.01

指数exponent: -1

基数radix(base): 2

**规格化:** 尾数最高有效位为 1. (即没有前导0), 为了*在尾数中表示最多的数据位*

**支持二进制科学计数法表示的数称为浮点数, 因为小数点可以浮动**

##### **IEEE754 存储结构**: 

$(符号位s\ 1bit,指数位exp\ 8\ bit,小数位frac\ 23\ bit)$--单精度float

$(-1)^s\times (1+fraction)\times 2^{exp-bias}$

​	frac中不存储前导的1, 因此实际可以存储**9**位. frac直接按位保存.

​	exp中使用**无符号**的方式存储, 使用**移码bias**来将其转化到有符号数.

###### **0的表示**

($exp=0,frac=0$)

有+0和-0之分(符号位不同)**. 但是**由于规格化数有一个前导1, 因此存在最小值$1.0\times 10^{-126}$**, 无法精确表示0, 因此当小于这个数的数**非规格化数表示**.

​	**单精度非规格化数**($e=0,f\neq 0$): exp=0, frac$\neq$0, 代表$(-1)^s\times 0.m\times2^{-126}$

###### **无穷的表示**: 

$exp=11\cdots11,frac=00\cdots00$, 有$+\infty$和$-\infty$之分(符号位不同)

###### **Nan的表示**:

 ($exp=11\cdots11,frac\neq 00\cdots00$)

##### 规格化

1. **左归**: 通过左移实现规格化.

#### 范围精度

**一般存储结构**: $(阶符1bit, 阶值m\ bit, 尾符1bit, 尾值n\ bit)$. *机器字长一定,**尾数越长**,精**确度越高,**但是表示的**范围越小***

**IEEE754 存储结构**: $(符号位s\ 1bit,指数位exp\ 8\ bit,小数位frac\ 23\ bit)$--单精度float

**单精度**: 1+8+23.

​	范围为:$2\times 10^{-38}<N<2\times 10^{38}$, **约为$2^{127}$**

**双精度**: 1+11+52

​	范围为:$2\times 10^{-308}<N<2\times 10^{308}$, **约为$2^{1230}$**

#### 运算(比较, 加法)

##### **比较**: 

1. 先比较符号位 2.剩余部分可以用unsigned比较器比较.

##### **加法**:	

 	1. 对阶, **小阶往大阶对**
 	2. 尾数加减
 	3. 规格化
 	4. 舍入
 	5. 检查溢出

#### 舍入 Rounding

**最近舍入: Round-To-Even**, 即向偶数(最低有效位为0)舍入

当数值处于中间时,要舍弃的位数形式为$100\cdots_2$, 就要向偶数舍入.

浮点计算时要**多保留一位(guard)保护位**, 因此IEEE754的frac实际可以表示24位,多保留一位就是25位. **当两个数阶码相差$\geq$25时, 可以不用计算而直接取大的数**

**Guard, Round, Sticky**: 最低有效位的后三位.Guard:最低有效位后一位, **Round**: Guard后一位. **Sticky**: Round后面一直到最后全为0则sticky为0,否则有一个1则为1.

**后规格化Postnormalize**: 如果舍入导致溢出, 就将结果**右移**并**增加exp**

### C语言中的浮点数

1. 单精度 float 1+8+23
2. 双精度 double 1+11+52

**浮点数转换**

1. double/float to int: 舍弃小数,向0舍入*.$\infty$和Nan都设置为Tmin*
2. int to double: 只要int的字长小于等于53bit就能精确转换
3. int to float: 根据不同的舍入模式来舍入

# 指令系统

## Lecture 04 指令集系统结构简介

### 指令集系统结构(ISA)

指令集与内部实现分开

#### 用户级和特权级指令

1. **用户级**: 用户态只能执行用户指令.
2. **特权级/系统级**: 所有程序都可见的指令.\

#### 设计ISA需要考虑的问题

1. ISA的乐星
2. 寻址方式
3. 操作数的类型和大小
4. 所支持的操作
5. 控制转移指令
6. 指令格式
7. $\cdots$

#### ISA的演进(四种典型结构)

1. **Accumulator**: 没有寄存器, 读取内存给加法器后将结果写回内存.
2. **Stack**: 通过栈进行加法器和内存的交互. 
3. **Register-Memory**; 对寄存器寻址, 两个造作书一个来自寄存器一个来自内存, *导致不同指令耗时不同*.
4. **Register-Register**: 必须先把内存内容读入寄存器, 结果也要先写入寄存器再写入内存. 读指令与运算符分开.

#### 存储器寻址

按**字节寻址**, 但是不同机器**对字word的定义是不同的**.

##### 将字节地址映射到字地址(大小端)

​			**Little Endian**: 数据低位从低字节开始放

​			**Big Endian**: 数据低位从高字节开始放

##### 字是否可存在字节的边界上(对其问题)

​			**边界对齐**: 若data size=s bit, 地址为A, 若**A%s=0**说明对齐. 

​			**边界对齐的原因**: 存储器的读写是边界对齐的. 不对齐的数据需要多次读写再拼接, 这降低了效率.

### 复杂指令集(CISC)和精简指令集(RISC)

#### CISC

指令数量多, 指令功能复杂

**主要问题**:

   				1. 指令数量太多, 无法直接做乱序执行
   				2. 不利于虚拟化
   				3. 指令长度为任意整数字节数

#### RISC

指令数量少, 指令功能单一

**MIPS指令的主要特征**:

   1. load/store型指令, 专门用于*寄存器和内存*间数据传输

   2. ALU指令的操作数只能来源于*寄存器和立即数*

      32个32位寄存器

##### **MIPS指令三种格式**:

1. **I 型**(immediate) 

$(op_{31-26},rs_{25-21},rt_{20-16},immediate_{15-0})$

1. ​	数据传输指令

   ​	lw和sw, 传入两个寄存器和一个偏移量

   1. 立即数指令

      代码中用到的值不太大的数, 直接在指令中包含它们比从存储器或寄存器中获取他们要快

   2. 条件转移指令

      bnq(branch not equal): 不相等就跳转

      beq(branch equal): 相等就跳转

2. **J 型**(jump)

3. **R 型**(register)

## Lecture 05 MIPS指令系统

### 指令概述

1. 32个32位寄存器,
2. 加减: add sub addi
3. 复制 add \$s0,\$1,\$zero
4. 寄存器与内存传输,lw, sw, offset=i*4(lw即load word); lb,sb, offset=any number
5. 逻辑指令: and or not sll(shift left) srl(shift right logic: 逻辑右移,高位填0) sra(shift right arithmetic: 算数右移,高位填符号位) 
6. 条件转移 beq(branch equal) bnq(branch not equal). *立即数为跳转到的指令与当前指令的下一条指令之间间隔的指令条数,因此要<<3*. 条件转移的极限位置为$2^{17}$bytes
7. 无条件转移 j(j指令的偏移量是绝对偏移量) jr jal(jump后将PC+4保存在\$ra中, ), jr(返回指令)
8. 比较大小: slt(set less than). beq和bnq总能是在slt之后进行条件转移 slti
9. 循环: do-while循环

### **过程执行的六个步骤**

1. 主程序将参数放置在过程可以访问到的位置
2. 调用程序将系统控制权给过程jal
3. 被调用过程申请所需的存储资源
4. 过程执行响应的任务
5. 过程将结果存在放结果寄存器中$v0-v1$
6. 被调用过程将系统控制权移交给调用程序

### 栈操作

1. 栈指针为寄存器\$sp

2. 栈**向下生长**, 即栈从高地址开始, 随着元素的加入不断添加, 栈指针不断减小.

3. 入栈, 入栈需要将\$sp减4.

   ```
   addi $sp,$sp,-4
   sw $s0,0($sp) #将$s0入栈
   ```

4. 出栈

   ```
   lw $s0,0($sp)
   addi $sp,$sp,4
   ```

### 过程调用的规范

<img src="C:\Users\69540\Documents\Tencent Files\695401454\FileRecv\MobileFile\IMG_1760(20210618-183732).PNG" alt="IMG_1760(20210618-183732)" style="zoom: 33%;" />

# 存储器层次结构

​	**Lecture 04 Machine Structure and Assembly**

## 指令执行过程

1. 取指令
2. 译码
3. 执行

## 局部性原理

1. 时间局部性: 最近访问的在不久的将来还会访问
2. 空间局部性: 当前访问项目地址邻近的项目可能会被访问

## 高速缓存(cache)的概念和地址映射方式

### cache基本思想

频繁访问的数据块存储在cache中而不是直接访问主存. 

### cache的基本概念

#### 块block

1. cache更小, 更快, 更贵
2. cache是内存以块为元素的一个子集
3. 数据以块为传输单位
4. **块block包含多个字的原因:** 局部性原理

#### 缓存命中 cache hit

需要访问的元素*所在的块*在cache中

#### 缓存失效 cache miss

需要访问的元素*所在的块*不在cache中, 需要从内存中将此**块**加载进cache. 这涉及到**防止策略**和**替换策略**

#### 缓存命中率 hit rate

$命中率h=\frac{N_c(通过cache完成访问的次数)}{N_c+N_m(cache失效不得不通过主存完成存取访问的总次数)}$

$平均访问时间t_a=ht_c(cache命中率\times cache访问时间)+(1-h)t_m(主存命中率\times 主存访问时间)$

### 数据查找: 如何判断一个元素是否在cache中

主存与cache有三种地址映射方式:(地址映射: 利用某种方法或者规则将主存块定位到cache)

**地址映射的理解:** 一个主存块映射到第1,2,3~ n 个cache块, 意味着一种权限, 即这个主存块可以被放到这n个cache块中的任意一个中. 

#### 直接映射

直接将主存块号$j$ 映射到cache块号$i$. 使用例如 $i=j\ mod\ n$的方法

**区**: 主存分割成若干个与cache大小相同的区, 每一个区中的主存块映射到同一个cache块.

需要在**地址中加入*区号***

<img src="C:\Users\69540\Documents\Tencent Files\695401454\FileRecv\MobileFile\712D3AAC222C1B689D18C5FC24C37DAD.png" alt="712D3AAC222C1B689D18C5FC24C37DAD" style="zoom:25%;" />

*块号* 为cache块号, 通过比较块号与区号来确定cache是否命中. 

*字地址* 既是cache内的偏移量, 也是区内的偏移量

**有效位valid bit**

表明某一个cache的entry是否有元素, 清楚cache的某一个entry只需要将valid bit设置为0. 

**字内偏移量**: 由于mips字长1word=32bits=4bytes, 最小寻址单元为byte, 因此有一个**2bit的字内偏移量用以选择一个word中的哪一个byte**

**标号tag**: data的一部分, 用以identify特定是数据. 用存储内容最为地址访问

##### 直接映射的优点: 

1. 地址变换速度块, 一对一映射
2. 替换算法简单

##### 直接映射的缺点:

1. 容易冲突(乒乓效应), cache的**利用率**低
2. **命中率**低

#### 全相联映射

每一个主存块都没映射到了**所有cache块**, 即可以放在任意一个cache块中, 主存不再分区. 而比较tag也需要和所有的cache块比较. 

<img src="C:\Users\69540\Documents\Tencent Files\695401454\FileRecv\MobileFile\IMG_1748(20210615-210547).PNG" alt="IMG_1748(20210615-210547)" style="zoom: 50%;" />

**比较器**的比较为线性遍历比较, 因此每次比较都必须遍历cache的每一个块. 

#### 全相联映射的优缺点

1. 一对多映射, cache全部充满后才会出现冲突
2. **块冲突概率低, cache利用率高**
3. 缺点在于相对的替换算法复杂

#### 组相联映射(set-associated)

**组**: 一个特定的主存块可以被任意方式的cache块的集合

**路**: 一个组内的cache块的个数

**byte line**即一个block的byte数量./

#### 两种分组方式

1. 常用的分组方式: 主存地 址mod 组数=组号. *不需要分区*
2. 不常用:  先将主存分成若干个与cache大小相同的区, 然后根据cache的分组方式在

#### 组相联映射的地址范围

<img src="C:\Users\69540\Documents\Tencent Files\695401454\FileRecv\MobileFile\CBE4A551F72387F5252B31F102E59508.png" alt="CBE4A551F72387F5252B31F102E59508" style="zoom:33%;" />

全相联映射是只有一个组, 关联度为cache块数的组相联

直接映射是有cache块数个组, 关联度为1的组相联

#### 组相联映射的应用场合

1. cache容量

   大容量: 直接映射, 大容量时路数的影响微乎其微

   小容量: 组相联或全相联, 越接近全相联失效率越低(组相联必须要先比较tag后再传出数据)

2. cache访问速度

   要求高: 直接映射

   要求低: 组相联或全相联


2. 确定了元素在cache中以后, 如何查找元素在cache的什么地方 
3. cache满了以后如何处理----替换策略
4. 如何确保cache和memory的一致性

### cache的组织结构

<img src="C:\Users\69540\Documents\Tencent Files\695401454\FileRecv\MobileFile\IMG_1746(20210615-202510).PNG" alt="IMG_1746(20210615-202510)" style="zoom:25%;" />

## Cache 更新策略

### Cache hit 时的写策略

1. **Write-through 写直达**: 时刻保持cache和memory的一致性

   内存数据必须先放入cache然后才能被CPU读取, CPU修改的内容同时写入memory和cache

   *Easier to make reliable since memory always has copy of data*

2. **Write-back 写回**: 推迟对内存的写入知道数据所在的缓存行被替换

   写回法需要在cache块种添加一个*重写标识为(dirty bit)*用于标记缓存中的行是否与内存种的相同

   修改的内容值写入cache, 不写入memory, 处理器只和cache打交道.

   当cache种的被修改的块被换出时更新memory

   *Usually reduces write traffic, harder to make reliable because sometimes has only copy of data*

   

### Cache miss的写策略

1. **Write-allocate 按写分配**: 将数据读入缓存, 在缓存中更新内容

   常与Write-Back搭配

   *大量存储器写操作时使用*

2. **No-write-allocate 不按写分配**:  直接修改内存中内容, 不需要读入缓存

   常与Write-Through搭配

   *当需要高安全性时使用*

   

## Cache替换策略

1. 随机替换
2. 先进先出FIFO
3. 近期最少使用 LRU $\star$
4. 最不常使用LFU
5. 伪LRU $\star$
6. 今日不常使用NMRU

### LFU

每块设置一个计数器, 每访问一次就将计数器加一, 每次将计数值最小的换出. 问题在于*新调入的很容易被换出*

### LRU

每块设置一个计数器, cache每命中一次就将计数器清零, 每次替换出值最大的. 

需要额外的硬件位来存储各块的状态, 这增加了cache的访问时间. 

**问题**在于N路需要N!个情况, 需要NlogN位来表达. 

### 伪LRU

基于树状结构, 1左0右

## 虚拟存储器与TLB

### 页表构成

1. Disk bit: 一个页是否在在磁盘中
2. 物理页号
3. Permission bit: 页的权限位, write-read-execute
4. Dirty bit: 这个页是否被写过
5. Valid bit: 页是否有效

 ### TLB 关联方式

1. 全相联: 小TLB
2. 组相联: TLB tag+TLB index(TLB的组号)+offset

## 页面失效

### TLB失效

如果本页已经载入内存, 就仅仅一次TLB miss, 只需要将信息从页表填入TLB, 一般花费<10个周期

### 页面失效(page fault)

本页没有载入内存, 需要从磁盘掉页, 一般要花费1000000个周期来处理页面失效

## 地址转换的组织结构

<img src="C:\Users\69540\Documents\Tencent Files\695401454\FileRecv\MobileFile\D8A62FC0C35D92A391E38C06377E7A80.png" alt="D8A62FC0C35D92A391E38C06377E7A80" style="zoom: 50%;" />

<img src="C:\Users\69540\Documents\Tencent Files\695401454\FileRecv\MobileFile\FD0166A0E9B14B7E9B42BD9AD4AE5BB6.png" alt="FD0166A0E9B14B7E9B42BD9AD4AE5BB6" style="zoom:50%;" />

## 高速缓存友好的代码

例如C语言中的数组元素是以**行row**位准顺序分配的, 同一行的元素被分配在连续的内存空间中. 

**关键思路**:

1. 让常用部分执行地更快: 核心函数的**内层循环**
2. 让缓存失效率最小
   1. 时间局部性: 重复引用同一变量
   2. 空间局部性: 优先访问邻近的变量

## Cache 性能分析

1. Access: 读或写缓存
2. Hit: 需要的数据在缓存中
3. Miss: 需要的数据不在缓存中
4. Fill: 将数据放入缓存中

### 性能指标

1. $失效率=\frac{miss}{access}$
2. $t_{access}$: access的时间, 检查一次缓存的时间
3. $t_{miss}$: 缓存失效所需要的代价

需要优化的量: **平均内存访问时间** $t_{avg}=t_{access}+(失效率\times t_{miss})$

### 优化方向

1. Decrease hit time: $t_{access}$. **方案**:
   1. 更小, 更简单的缓存
   2. 直接映射寻址(比较与传出数据可以并行完成)
   3. 更小的块
   4. 增加**write  buffer**(一种高速存储, 将要写入内存的数据先写入write buffer中, 等CPU空闲时再写入内存)Pre
   5. Prefetch(预取):  (*预取现在大多数由硬件完成, 但是**不定步长的预取**只能由软件完成*)
      1. 当L1 miss后,从L2取数据时多取一块到stream buffer中. 下一次若L1miss但是在stream buffer中hit, 则再多取一块到stream buffer中.
      2. 若每次miss的步长一样, 则可以计算步长. 每次预取特定步长(stride)的块.
2. Decrease miss rate
   1. 更大的缓存
   2. 更复杂的放置策略(增大关联度, 减少冲突)
   3. 更大的块
   4. 增加**victim cache**: 较小的buffer, 用于存放最近从cache中排出的块
   5. 编译优化(例如*归并数组*来增加*空间局部性*, *循环合并*来增加*时间局部性*)
3. Decrease miss penalty: $t_{miss}$
   1. 更小的块(每次miss要传入更少的数据)
   2. 使用**write buffer**
   3. 读的优先级比写的优先级更高
   4. 对于large blocks fetch:
      1. early start
      2. critical word first
   5. 不阻塞缓存
   6. 使用多级缓存

问题在于这三个方向之间有trade-off:

1. small and simple caches: 会减少hit time(因为降低了电路复杂性), 但是会增大miss rate
2. large block size: miss rate降低(发挥了空间局部性) , 但是增大了miss penalty(因为每次需要传入更多的数据)
3. high associativity: miss rate降低, 但是查找的时间增大. *当路很多时通过增加关联度提升的就很少*

### 设计缓存层级

1. **上层缓存(L1)**: *重视**降低hit时间$t_{access}$***. 因为上层缓存访问频繁而miss的代价不很高
   1. 更小的cache容量
   2. 更低的关联度
   3. 中小型的块
2. **下层缓存(L2,L3)**: *重视**降低失效率$miss\ rate$***. 因为下层缓存访问不频繁但是miss的代价很高.
   1. 更大的容量
   2. 更高的关联度
   3. 更大的block

# 处理器设计(单周期)

**单周期处理器**: 一个时钟周期完成一条指令.

## 三种周期及其关系 

**CPU周期(机器周期)**: 完一条指令的执行过程被分为了五段, 执行每一段的时间叫机器周期

**时钟周期**: 计算机内部*最小*周期单位

**指令周期**: 计算机从取指令到执行完毕的时间



## 状态单元

每一个周期更新一次, 是否更新需要一个**显式的控制信号**, 边沿触发(状态的转换发生在**时钟的边沿**)

### 寄存器

![image-20210611183421785](C:\Users\69540\AppData\Roaming\Typora\typora-user-images\image-20210611183421785.png)

### 存储器

![image-20210611183510480](C:\Users\69540\AppData\Roaming\Typora\typora-user-images\image-20210611183510480.png)

## 选择组件构成数据通路

### 取指令

每次将PC传入指令存储器后将其加4(下一个指令的地址)

![image-20210611183704759](C:\Users\69540\AppData\Roaming\Typora\typora-user-images\image-20210611183704759.png)

### 指令译码

![image-20210611183857875](C:\Users\69540\AppData\Roaming\Typora\typora-user-images\image-20210611183857875.png)

将指令的op和funct传给控制器以生成控制信号.

寄存器地址传入RA和RB

# 流水线处理器的原理

1. setup time: 输入信号在时钟边沿**前**必须稳点的时间
2. hold time: 输入信号在时钟边沿**后**必须稳定的时间
3. clk-to-q time: 输出信号在时钟边沿后状态改变前必须稳定的时间\

## 流水线中的相关性与"冒险"

### 结构冒险(structural hazards)

所诉的硬件部件正在为之前的指令工作.

**避免结构冒险的方法**:

1. 增加硬件资源
2. 功能单元流水化

**两个结构冒险的例子**

1. *如果只有一个存储器*
   1. 方案1: 插入空指令
   2. 方案2: 指令存储器和数据存储器相互独立
   3. 方案3: 使用缓存来解决结构冒险
2. 寄存器文件存在结构冒险
   1. 读写口独立的寄存器文件. 写寄存器在一个周期的前半段完成, 读寄存器在一个周期的后半段完成

### 数据冒险

当一条指令需要等待之前的指令完成数据的读写. 

1. 方案1(NOP): 一种简单的软件解决方案: 插入空指令

2. 方案2(Stall): 一种简单的硬件解决方案: 流水线停顿(当一条指令被暂停时, 暂停在其后发射的指令, 但继续在其前发射的指令)
3. 方案3(Forwarding): 前向传递, 将前面指令的结果直接从产生的地方定向到当前指令所需的位置. 但是*前向通路不能解决<读存储器-使用>问题*

### 控制冒险

由转移指令引起, 当转移指令的结果还未确定时, 无法确定下一步执行哪条指令.

1. **无条件转移指令引发的控制冒险**

   无条件转移指令在ID译码段就可以得出结果, 只需要浪费一个周期.

   Jump指令的CPI=2

2. **条件转移指令(分支指令)引发控制冒险**

   新的PC值在MEM访存段才写入, 需要浪费三个周期.

   Branch指令的CPI=4

   可以使用**分支提前决策**(把=0?的测试移到ID段, 并在ID段增加一个加法器计算转移目标地址). 使用转移预测只能在ID段以后知道结果, 仍然需要浪费一个周期, CPI=0. 

   **转移延迟**: 将n条与branch无关的指令插在branch指令后面, 这n条指令就是转移延迟槽. 无论分支是否执行, 都必须在branch指令后执行完转移延迟槽中的内容. 但是并不是每次都有足够的不相关指令可以放在branch指令后面, 最坏情况下只能插入若干条空指令.

### 流水线处理器的性能

$CPU执行时间=指令数目\times 平均每条指令的CPI(CPI_{ideal}+CPI_{stall})\times 一个时钟周期的长度$

### 转移预测



# 指令集并行

## 静态多发射: 超长指令字(VLIW: Very Long Instruction Word)

<img src="C:\Users\69540\Documents\Tencent Files\695401454\FileRecv\MobileFile\BE992DF4DC6F2F674B17FBD320CD9A15.png" alt="BE992DF4DC6F2F674B17FBD320CD9A15" style="zoom:50%;" />

1. 双发射MIPS处理器: 将一两个32位指令打包成一个64位指令束.
2. 指令束中的指令**成对**取值, 译码和发射
   3. 由**编译器**安排指令束. 选取每次同时发射的两条指令
  4. *如果找不到合适的指令, 就用空指令NOP来替代*
 5. **在一个长指令上的两条指令必须无关**

### VLIW 的优点

1. 硬件简单: 只需要增加一个ALU或加法器来计算内存地址
2. 成本低
3. 能耗少

### VLIW的缺点

1. 编译复杂: 需要进行**循环展开, 冲突检测, 指令调度**, 并且将**if-else结构转化为可预测的转移指令**, 还要进行**存储器访问地址的预测**.
2. 代码膨胀: 空指令**浪费了存储空间**. 需要先把**循环展开**这也浪费了存储空间. 
3. 锁步机制: 一条指令阻塞那么其后所有的指令都阻塞. **相关性解除才允许发射相关的指令**, 但是流水段数越多, 则相关性越多.
4. 目标代码不不兼容: 需要提前设计体系结构, 市场接受度差

## 超标量(动态多发射)

### 按序超标量(静态超标量)

**先取的指令先进入, 后取的指令后进入.同时发射的指令走相同的步骤执行完.**

如A8处理器: *静态调度*, 动态发射, *按序超标量*

1. **静态调度:** **编译器**尽力避免: 1. ***结构冒险***(两条指令使用同一部件) 2. ***数据相关性***(两条指令有数据依赖关系)
2. **动态发射**: 在**运行时**才决定那两条指令可以并行
   - 每个周期由控制逻辑判断**发射一条指令or两条指令or不发射指令**
   - **结构冒险:** 当编译器无码避免时, **能检测出冒险**, 一次只发射一条指令
   - **数据冒险:** 同上, 检测出冒险. 如果有冒险, 就**将两条or一条指令停顿**
   - **控制冒险:** 当**转移预测错误时, 清空流水线**, 并从正确的位置开始执行.

### 乱序超标量(动态超标量)

#### 1. 与静态超标量的主要差别:

指令能否乱序执行.

#### 2. 乱序超标量比之按序超标量的优点

按序超标量中, 一起取的指令必须一起执行. 如果同时取的指令执行速度不同, 那么先完成的指令实际上可以提前结束执行.

<img src="C:\Users\69540\Documents\Tencent Files\695401454\FileRecv\MobileFile\A5E7C12598376C317A2A6B94732281AA.png" alt="A5E7C12598376C317A2A6B94732281AA" style="zoom:33%;" />

上图第一条指令只需要一个周期, 但是第四条指令需要四个周期. 在按序超标量中第一条指令必须等待四个周期才能写回.

但是在乱序超标量中(如下图), **先完成的指令可以先结束, 将流水部件给到新的指令**

<img src="C:\Users\69540\Documents\Tencent Files\695401454\FileRecv\MobileFile\E3C924A294556A96D51E561E8480EA3F.png" alt="E3C924A294556A96D51E561E8480EA3F" style="zoom:33%;" />

#### 3. 乱序超标量的相关性问题

##### a. 数据假相关

**数据假相关**: 两条指令之间并没有实际上的数据依赖性, 只是因为修改寄存器的顺序不同导致读写错误. 

  1. **输出相关**(**WAW**-Write after write 写后写相关): 写同一个寄存器的指令乱序执行导致最终写入寄存器的值错误, 后面的读取寄存器的指令也随之错误(*寄存器最后被写入的值不是应该需要的值*)

     如:两个写\$t0的lw指令乱序.

  2. **反相关**(**WAR**-Write after read 写后读相关): 应该先读再写, 实则先写再读.

     <img src="C:\Users\69540\AppData\Roaming\Typora\typora-user-images\image-20210619210116379.png" alt="image-20210619210116379" style="zoom:33%;" />

     **输出相关和反相关的解决方法:** **寄存器换名**, 输出相关和反相关只是*改寄存器的顺序不同导致的问题, 实际上两条指令间并没有数据依赖性. 即, 后面的指令并不需要前面的指令的结果*

##### b. 数据真相关

**数据真相关:**(**RAW**-Read after write 读后写相关) 前面的指令写寄存器, 后面的指令读寄存器 ,后面的执行需要前面指令的执行结结束才能继续执行. 无法通过换名来解决. 

#### 4. 乱序超标量处理器的结构

<img src="C:\Users\69540\AppData\Roaming\Typora\typora-user-images\image-20210619220134515.png" alt="image-20210619220134515" style="zoom: 67%;" />

1. 取指, 译码, **寄存器换名**后将指令分配到**指令窗口中**
2. 指令窗口来**分配**决定哪些指令可以**并行乱序执行**
3. 并行的指令仍然按照流水执行
4. 先完成的指令**先写入缓存区中**, 最后在统一的提交点**按序提交**(因为处理器在Write-Back阶段才能给系统发送中断)
5. 在按序提交前进行指令完成的**异常检测**

# 数据级并行性

## SISD

**单指令单数据(Single instrcution single data)**： 指令顺序执行, 指令和数据都没有并行性. 一次一条指令, 一条指令处理一个数据流(例如做一次加法)

例如: 我们学习的MIPS处理器

## SIMD

**单指令多数据流(Single instruction multiple data streams**: 一条指令可以处理多个数据流(例如一条指令做四个加法) 

如下图所示, 一条指令将数据传给多个可以并行处理的Process Unit(处理单元).

<img src="C:\Users\69540\Documents\Tencent Files\695401454\FileRecv\MobileFile\C40ABD7D6915CF0DFFBF95714D4E0ED1.png" alt="C40ABD7D6915CF0DFFBF95714D4E0ED1" style="zoom:50%;" />

### 向量处理机模型
#### 1. 向量处理机的基本思想

两个向量对应的分量进行运算, 产生一个向量化的结果.

#### 2. 向量处理机的基本特征

1. 一条指令包含**多个操作**

2. 单条向量指令内的操作**相互独立**

3. 以已知模式访问存储器——**多体交叉存储器**

4. **控制相关性少**

#### 3. 向量处理机的基本结构

1. 向量指令**并行执行**
2. 向量**运算部件**的执行方式: 
   1. 深度流水线方式->快时钟
   2. 简化流水线的控制因为向量中的元素是独立的, **没有数据冒险, 不需要旁路(bypass)**
3. 向量**部件结构**: 多道结构-多条运算流水线

#### 4. 数据存储: 多体交叉存储器

**多体交叉存储器**: 相邻数据存储在不同的体中, 体可以同时访问, 但是受限于bus宽度必须要依次取出. 它**降低了取数据的延迟**, 除了第一个以外其他的数据只需要付出数据在在总线上流过的时间.

<img src="C:\Users\69540\Documents\Tencent Files\695401454\FileRecv\MobileFile\5529A0480DEC87ECEF33251D11D7B5FA.png" alt="5529A0480DEC87ECEF33251D11D7B5FA" style="zoom: 33%;" />

#### 5. 向量连接 Vector Chaining

**向量连接**: 旁路(bypass), 上一个指令的结果直接送到下一个指令的运算单元.

<img src="C:\Users\69540\Documents\Tencent Files\695401454\FileRecv\MobileFile\F8900CE1A220E90327E086F20A615048.png" alt="F8900CE1A220E90327E086F20A615048" style="zoom: 33%;" />

#### 6. 向量条件转移: 掩码(Mask bit)

**简单实现**: 所有操作都执行, 通过掩码来决定哪些数据写入.

**Density-Time 实现**: 通过掩码来选择需要的运算执行, 不需要的运算就不执行了.

## MIMD

**多指令多数据流(Multiple instruction multiple data streams)**: 多个处理单元同时执行多条指令来处理多个数据流. 

即**多线程**, 程序员需要兼顾多个线程.

<img src="C:\Users\69540\Documents\Tencent Files\695401454\FileRecv\MobileFile\EBA2B6D5C1816CE06FC6F13D32E426FE.png" alt="EBA2B6D5C1816CE06FC6F13D32E426FE" style="zoom:50%;" />

## MISD

**多指令单数据流(Multiple instruction single data stream)**: 现在几乎不适用, 不包含在本课程的范围内.

## GPU

### 1. CPU与GPU对比

**CPU:** 强控制弱计算. 因为CPU的芯片给了太多空间给控制单元和cache, 运算单元ALU比较少.

<img src="C:\Users\69540\AppData\Roaming\Typora\typora-user-images\image-20210620005812123.png" alt="image-20210620005812123" style="zoom:50%;" />

**GPU:** 弱控制强计算

<img src="C:\Users\69540\AppData\Roaming\Typora\typora-user-images\image-20210620005838121.png" alt="image-20210620005838121" style="zoom: 50%;" />

 ### 2. 编程模型: SPMD

每个处理单元执行**同样的过程**, 处理**不同的数据**.

### 硬件执行模型



# 多线程处理器与线程级并行

## 粗粒度多线程

**CPU执行一个线程, 高速缓存失效时才切换线程**(应用不多, ***考试不考***)

## 细粒度多线程

**每个周期都切换**

## 同时多线程

**多个线程并行执行, 没有切换一说**



